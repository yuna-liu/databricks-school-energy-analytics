{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "723176ff-abbf-4352-b726-cd5795c83b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Design note\n",
    "\n",
    "This pipeline intentionally parses files one-by-one using a Python loop.\n",
    "Reason:\n",
    "- Header length varies per file\n",
    "- Key-value pairs are not uniform\n",
    "- Row-based Spark ingestion caused pivot explosion\n",
    "\n",
    "This is a conscious design choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "311beb8a-edf5-4886-a448-2c9112191d40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "silver.energy_header\n",
    "- One row per source file\n",
    "- Parsed from file header section\n",
    "- Header length may vary per file\n",
    "\n",
    "silver.energy_measurements\n",
    "- Long format\n",
    "- One row per timestamp per variable\n",
    "- Parsed from measurement section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dad5116d-3fec-406b-826d-880e55b506ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## School Energy ML Dimension loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50056b43-af03-4d4c-b7b9-40afb86a95ea",
     "showTitle": false,
     "tableResultSettingsMap": {
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764847095535}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from pyspark.sql import Row\n",
    "\n",
    "desired_columns = [\n",
    "    'Header_line', 'location', 'year_of_construction', 'floor_area', 'number_of_users', 'building_category', 'dhw_heat_source', 'sh_heat_source',\n",
    "    'timestamp_format', 'timezone', 'building_id'\n",
    "]\n",
    "\n",
    "# Add 'file_name' to desired columns\n",
    "final_columns = desired_columns + ['file_name']\n",
    "\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .load(\"/Volumes/school_energy_ml/bronze/raw_energy\")\n",
    ")\n",
    "\n",
    "first_line = df.first()[0]\n",
    "first_line_split = first_line.strip().split(\";\")\n",
    "read_rows = int(first_line_split[1]) - 0\n",
    "\n",
    "file_paths = glob.glob(\"/Volumes/school_energy_ml/bronze/raw_energy/*.txt\")\n",
    "display(file_paths)\n",
    "result_rows = []\n",
    "all_header_rows = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = spark.read.text(file_path)\n",
    "    header_rows = df.limit(read_rows).collect()\n",
    "    all_header_rows.extend(header_rows)\n",
    "    columns = [row.value.split(\";\", 1)[0].strip() for row in header_rows]\n",
    "    values = [row.value.split(\";\", 1)[1].strip() if \";\" in row.value else \"\" for row in header_rows]\n",
    "    filtered = {col: val for col, val in zip(columns, values) if col in desired_columns}\n",
    "    # Add file name to the row\n",
    "    row_with_file = [filtered.get(col, \"\") for col in desired_columns] + [file_path]\n",
    "    result_rows.append(row_with_file)\n",
    "\n",
    "result_df = spark.createDataFrame(result_rows, final_columns)\n",
    "display(result_df) \n",
    "result_df.write.mode(\"overwrite\").saveAsTable(\"school_energy_ml.silver.energy_header\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6432af6-6311-42a9-bf30-92fc8dcab3f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## School Energy ML Fact data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69ee9cc8-6620-46c7-8e55-0d7dcb2c341d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "import glob\n",
    "\n",
    "# Get all file paths\n",
    "file_paths = glob.glob(\"/Volumes/school_energy_ml/bronze/raw_energy/export_*.txt\")\n",
    "\n",
    "dfs = []\n",
    "all_columns = set()\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Read first line to get skip_rows\n",
    "    first_line = spark.read.text(file_path).first()[0]\n",
    "    first_line_split = first_line.strip().split(\";\")\n",
    "    skip_rows = int(first_line_split[1])\n",
    "\n",
    "    # Read header row using DataFrame limit (no RDD)\n",
    "    header_row = (\n",
    "        spark.read.text(file_path)\n",
    "        .limit(skip_rows)\n",
    "        .collect()[-1]\n",
    "        .value\n",
    "    )\n",
    "    header = [col.strip() for col in header_row.split(\";\")]\n",
    "\n",
    "    # Read actual data and add file_name column\n",
    "    df = (\n",
    "        spark.read\n",
    "        .option(\"delimiter\", \";\")\n",
    "        .option(\"inferSchema\", True)\n",
    "        .option(\"skipRows\", skip_rows + 1)\n",
    "        .csv(file_path)\n",
    "        .toDF(*header)\n",
    "        .withColumn(\"file_name\", lit(file_path))\n",
    "    )\n",
    "\n",
    "    dfs.append(df)\n",
    "    all_columns.update(header)\n",
    "\n",
    "# Add 'file_name' to all_columns\n",
    "all_columns = list(all_columns) + [\"file_name\"]\n",
    "standardized_dfs = []\n",
    "\n",
    "for df in dfs:\n",
    "    for col in all_columns:\n",
    "        if col not in df.columns:\n",
    "            df = df.withColumn(col, lit(None))\n",
    "    df = df.select(*all_columns)\n",
    "    standardized_dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "final_df = standardized_dfs[0]\n",
    "for df in standardized_dfs[1:]:\n",
    "    final_df = final_df.unionByName(df, allowMissingColumns=True)\n",
    "\n",
    "#display(final_df)\n",
    "final_df.write.mode(\"overwrite\").saveAsTable(\"school_energy_ml.silver.energy_measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00a2dd9c-bea5-4aef-98fb-0e750fd42942",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764436680973}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from school_energy_ml.silver.energy_measurements\n",
    "where HtBio is not null\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4138211599386137,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_silver_dm_and_fact_tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
